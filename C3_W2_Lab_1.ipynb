{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e30dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, tensorflow_hub as hub, numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49af526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inception resnet version 2\n",
    "module_handle = \"https://kaggle.com/models/tensorflow/faster-rcnn-inception-resnet-v2/frameworks/TensorFlow2/variations/640x640/versions/1\"\n",
    "model = hub.load(module_handle)\n",
    "\n",
    "# take a look at the available signatures for this particular model\n",
    "model.signatures.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a129de",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"./dublin014.jpeg\"\n",
    "\n",
    "# 1. Read and Decode (Output: tf.uint8)\n",
    "image_bytes = tf.io.read_file(img_path)\n",
    "image_tensor_uint8 = tf.image.decode_jpeg(image_bytes, channels=3)\n",
    "\n",
    "# 2. Convert to Float for Resizing\n",
    "# Resizing functions in TF typically operate on float tensors.\n",
    "image_tensor_float = tf.image.convert_image_dtype(image_tensor_uint8, tf.float32)\n",
    "\n",
    "# 3. Resize (Output: tf.float32)\n",
    "# Remove the problematic 'dtype=tf.uint8' argument.\n",
    "# Note: tf.image.resize expects a rank 3 (H, W, C) tensor.\n",
    "resized_image_float = tf.image.resize(\n",
    "    image_tensor_float, \n",
    "    [256, 256], \n",
    "    method='lanczos3'\n",
    ")\n",
    "\n",
    "# 4. Convert back to tf.uint8 for the detector\n",
    "# This step is critical because your model signature requires tf.uint8 (0-255).\n",
    "# The resize operation scaled the values to [0.0, 1.0], so converting back\n",
    "# to uint8 automatically scales them back to [0, 255].\n",
    "final_image_uint8 = tf.image.convert_image_dtype(resized_image_float, tf.uint8)\n",
    "\n",
    "# 5. Run Detector\n",
    "# Add the batch dimension [tf.newaxis, ...]\n",
    "results = detector(final_image_uint8[tf.newaxis, ...])\n",
    "result = {key:value.numpy() for key,value in results.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b702dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# COCO Label Map (The model is trained on a COCO-like dataset)\n",
    "# We only need the ID-to-name mapping. IDs are 1-based.\n",
    "# ----------------------------------------------------------------------\n",
    "# NOTE: The model outputs classes as 1-90, but the list is 0-indexed.\n",
    "# The `detection_classes` tensor has values 1-90. We use list index (ID-1)\n",
    "# to get the name.\n",
    "COCO_CLASSES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', \n",
    "    'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', \n",
    "    '__skip__', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', \n",
    "    'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "    '__skip__', 'backpack', 'umbrella', '__skip__', '__skip__', 'handbag', \n",
    "    'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', \n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', \n",
    "    'tennis racket', 'bottle', '__skip__', 'wine glass', 'cup', 'fork', \n",
    "    'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', \n",
    "    'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', \n",
    "    'couch', 'potted plant', 'bed', '__skip__', 'dining table', '__skip__', \n",
    "    '__skip__', 'toilet', '__skip__', 'tv', 'laptop', 'mouse', 'remote', \n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', \n",
    "    'refrigerator', '__skip__', 'book', 'clock', 'vase', 'scissors', \n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n",
    "\n",
    "\n",
    "def visualize_detections(image_tensor, result_dict, score_threshold=0.5, max_detections=10):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes and labels on the image for top detections.\n",
    "\n",
    "    Args:\n",
    "        image_tensor (tf.Tensor): The original image tensor (H, W, 3, tf.uint8).\n",
    "        result_dict (dict): Dictionary of numpy arrays from model inference.\n",
    "        score_threshold (float): Minimum score to display a detection.\n",
    "        max_detections (int): Maximum number of detections to display.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Filter and Prepare Results ---\n",
    "    \n",
    "    # Remove the batch dimension (axis 0) from all outputs\n",
    "    boxes = result_dict['detection_boxes'][0]      # shape (100, 4)\n",
    "    scores = result_dict['detection_scores'][0]    # shape (100,)\n",
    "    classes = result_dict['detection_classes'][0].astype(int) # shape (100,)\n",
    "    \n",
    "    # Apply score threshold and max detections limit\n",
    "    # We use numpy indexing for efficient filtering\n",
    "    valid_indices = np.where(scores >= score_threshold)[0]\n",
    "    \n",
    "    # Limit to the top 'max_detections' based on sorted scores\n",
    "    top_indices = valid_indices[np.argsort(scores[valid_indices])[::-1]][:max_detections]\n",
    "    \n",
    "    final_boxes = boxes[top_indices]\n",
    "    final_scores = scores[top_indices]\n",
    "    final_classes = classes[top_indices]\n",
    "\n",
    "    # --- 2. Setup Plotting ---\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(10, 10), dpi=300)\n",
    "    # Matplotlib needs a numpy array\n",
    "    ax.imshow(image_tensor.numpy())\n",
    "    \n",
    "    height, width, _ = image_tensor.shape\n",
    "    \n",
    "    # --- 3. Draw Bounding Boxes ---\n",
    "    \n",
    "    for i in range(len(final_boxes)):\n",
    "        ymin, xmin, ymax, xmax = final_boxes[i]\n",
    "        score = final_scores[i]\n",
    "        class_id = final_classes[i]\n",
    "        \n",
    "        # Convert normalized coordinates (0-1) to absolute pixel values\n",
    "        x = xmin * width\n",
    "        y = ymin * height\n",
    "        w = (xmax - xmin) * width\n",
    "        h = (ymax - ymin) * height\n",
    "        \n",
    "        # Get the class label\n",
    "        # Class IDs are 1-based, so use index (ID - 1)\n",
    "        label = f\"{COCO_CLASSES[class_id]}: {score:.2f}\"\n",
    "        \n",
    "        # Create a Matplotlib rectangle patch (green for visibility)\n",
    "        rect = plt.Rectangle((x, y), w, h, \n",
    "                             fill=False, \n",
    "                             edgecolor='g', \n",
    "                             linewidth=1)\n",
    "        ax.add_patch(rect)\n",
    "        \n",
    "        # Add the label text above the box\n",
    "        ax.text(x, y - 5, label, \n",
    "                color='white', \n",
    "                fontsize=5, \n",
    "                bbox=dict(facecolor='g', alpha=0.6, pad=2))\n",
    "\n",
    "    ax.set_title(f\"Object Detection Results (Top {len(final_boxes)} Detections)\")\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Execute Visualization\n",
    "# ----------------------------------------------------------------------\n",
    "# We need the original, decoded, but UNRESIZED image tensor for the visualization\n",
    "# to get the correct absolute coordinates.\n",
    "original_image_bytes = tf.io.read_file(img_path)\n",
    "original_image_tensor = tf.image.decode_jpeg(original_image_bytes, channels=3)\n",
    "\n",
    "# Run the visualization with the results and the image\n",
    "visualize_detections(original_image_tensor, result, score_threshold=0.5, max_detections=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b62897e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Glob Venv (TF-ML)",
   "language": "python",
   "name": "glob_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
